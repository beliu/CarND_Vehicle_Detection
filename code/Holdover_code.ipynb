{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some helper functions for convenience\n",
    "\n",
    "def read_files(data_dir, shuffle=False):\n",
    "    image_files = glob.glob(data_dir)\n",
    "    image_files = np.array(image_files)\n",
    "    if shuffle:\n",
    "        image_files = shuffle(image_files)\n",
    "        \n",
    "    return image_files\n",
    "   \n",
    "def show_images(image_files, bounds=[None, None], num_img=10):\n",
    "    for img_file in image_files[:10]:\n",
    "        fig = plt.figure()\n",
    "        img = mpimg.imread(img_file)\n",
    "        if all(bounds):\n",
    "            img = img[row.ymin:row.ymax, row.xmin:row.xmax]\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "        plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the car positions from the images\n",
    "udacity_cars = udacity_data.loc[udacity_data.label==\"car\"]\n",
    "udacity_cars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Using the GTI/KITTI Dataset\n",
    "\n",
    "# Extract the vehicle image file names from the various directories\n",
    "data_dir = \"./Dataset/vehicles/\"\n",
    "far_image_files = read_files(data_dir + \"GTI_Far/*.png\")\n",
    "left_image_files = read_files(data_dir + \"GTI_Left/*.png\")\n",
    "close_image_files = read_files(data_dir + \"GTI_MiddleClose/*.png\")\n",
    "right_image_files = read_files(data_dir + \"GTI_Right/*.png\")\n",
    "kitti_image_files = read_files(data_dir + \"KITTI_extracted/*.png\")\n",
    "vehicle_image_files = np.concatenate((far_image_files, left_image_files, close_image_files, right_image_files,\n",
    "                                      kitti_image_files, udacity_car_filenames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the non-vehicle image file names\n",
    "data_dir = \"./Dataset/non_vehicles/\"\n",
    "extra_image_files = read_files(data_dir + \"Extras/*.png\")\n",
    "GTI_image_files = read_files(data_dir + \"GTI/*.png\")\n",
    "udacity_non_cars = udacity_data.loc[udacity_data.label!=\"car\"]\n",
    "udacity_non_car_files = udacity_non_cars[\"Filename\"].values\n",
    "non_vehicle_image_files = np.concatenate((extra_image_files, GTI_image_files, udacity_non_car_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Shuffle the images so that that training and test set have a balanced number of the far, close, \n",
    "# left, right types of GTI car images and also a balanced number of the Udacity and KITTI car images\n",
    "\n",
    "# Create temporary labels for the different kinds of car images and one label for the non-car images\n",
    "labels = ([0] * len(far_image_files) + [1] * len(left_image_files) + [2] * len(close_image_files) + \n",
    "          [3] * len(right_image_files) + [4] * len(kitti_image_files) + [5] * len(udacity_car_filenames) +\n",
    "          [6] * len(non_vehicle_image_files))\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Constructing the Neural Network. The following creates a class that contains helper functions \n",
    "# for creating the CNN, its cost and optimizer functions, and for training the network\n",
    "\n",
    "class CNN:\n",
    "    \n",
    "    def __init__(self):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "    # Create a generator to get batches of the dataset - assuming use of Udacity dataset only\n",
    "    def get_batches(self, X, y, batch_size):\n",
    "        '''\n",
    "            A generator that supplies batches of data to the Neural Network model\n",
    "            Parameters:\n",
    "                X: The input dataset\n",
    "                y: the labels for each row of the dataset\n",
    "                batch_size: how many rows are in each batch\n",
    "            Returns:\n",
    "                X_out: a batch, of length batch_size, of the dataset\n",
    "                y_out: the corresponding labels to the batch output\n",
    "        '''\n",
    "        for ii in range(0, len(X), batch_size):\n",
    "            X_out = []    # List for storing the extracted image array\n",
    "            for row in X[ii:ii + batch_size]:\n",
    "                # Extract the image filename and bounded box coordinates\n",
    "                file, xmin, ymin, xmax, ymax = row\n",
    "                img = mpimg.imread(file)\n",
    "                img = img[ymin:(ymax + 1), xmin:(xmax + 1)]\n",
    "                img = cv2.resize(img, (64, 64))\n",
    "                X_out.append(img)\n",
    "            \n",
    "            X_out = np.array(X_out)\n",
    "            y_out = y[ii:ii + batch_size]\n",
    "\n",
    "            yield X_out, y_out\n",
    "\n",
    "    def get_model_inputs(self, n_classes):\n",
    "        '''\n",
    "            Create the tensorflow input and label placeholders\n",
    "            Parameters:\n",
    "                n_classes: The number of classes in the dataset\n",
    "            Returns:\n",
    "                input_x: The placeholder for the input batch of image arrays\n",
    "                labels_y: The placeholder for the corresponding labels    \n",
    "                is_training: The placeholder for the batch_normalization training flag\n",
    "        '''\n",
    "    \n",
    "        input_x = tf.placeholder(tf.float32, (None, 64, 64, 3))\n",
    "        labels_y = tf.placeholder(tf.float32, (None, n_classes)) \n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "        return input_x, labels_y, is_training\n",
    "\n",
    "    def build_network(self, input_x, is_training, n_classes, alpha=0.2):\n",
    "        '''\n",
    "            Build the Convolutional Neural Network to classify the images\n",
    "            Parameters:\n",
    "                input_x: The input image data\n",
    "                is_training: For use in batch normalization. If True, then use batch statistics.\n",
    "                          If False, then use population statistics\n",
    "                n_classes: The number of classes in the dataset\n",
    "                alpha: Parameter to tune Leaky ReLU\n",
    "            Returns:\n",
    "                logits: The output of the CNN, flattened to a vector of length equal to the number of classes (4 here)\n",
    "        '''\n",
    "        # Input shape is 64x64x3\n",
    "        # First Convolution Layer, no batch normalization\n",
    "        x1 = tf.layers.conv2d(input_x, filters=64, kernel_size=3, strides=1, padding=\"same\")\n",
    "        x1 = tf.layers.max_pooling2d(x1, pool_size=2, strides=2)\n",
    "        x1 = tf.maximum(x1, alpha * x1) # Output shape is 32x32x64\n",
    "\n",
    "        # Second Convolution Layer, with batch normalization\n",
    "        x2 = tf.layers.conv2d(x1, filters=128, kernel_size=3, strides=1, padding=\"same\")\n",
    "        x2 = tf.layers.max_pooling2d(x2, pool_size=2, strides=2)\n",
    "        x2 = tf.layers.batch_normalization(x2, training=is_training)\n",
    "        x2 = tf.maximum(x2, alpha * x2) # Output shape 16x16x128\n",
    "\n",
    "        # Third Convolution Layer, with batch normalization\n",
    "        x3 = tf.layers.conv2d(x2, filters=256, kernel_size=3, strides=1, padding=\"same\")\n",
    "        x3 = tf.layers.max_pooling2d(x3, pool_size=2, strides=2)\n",
    "        x3 = tf.layers.batch_normalization(x3, training=is_training)\n",
    "        x3 = tf.maximum(x3, alpha * x3) # Output shape 8x8x256\n",
    "\n",
    "        # Fourth Convolution Layer, with batch normalization\n",
    "        x4 = tf.layers.conv2d(x3, filters=512, kernel_size=3, strides=1, padding=\"same\")\n",
    "        x4 = tf.layers.max_pooling2d(x4, pool_size=2, strides=2)\n",
    "        x4 = tf.layers.batch_normalization(x4, training=is_training)\n",
    "        x4 = tf.maximum(x4, alpha * x4) # Output shape 4x4x512\n",
    "        x4_shape = x4.get_shape().as_list()[1:]\n",
    "\n",
    "        # Flatten the tensor and pass through a fully-connected layer\n",
    "        flat = tf.reshape(x4, (-1, x4_shape[0] * x4_shape[1] * x4_shape[2]))\n",
    "        logits = tf.layers.dense(flat, units=n_classes, activation=None)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def get_model_loss(self, logits_x, labels_y):\n",
    "        '''\n",
    "            Create the model loss function\n",
    "            Parameters:\n",
    "                logits_x: logits from the neural network\n",
    "                labels_y: corresponding labels for the input\n",
    "            Returns:\n",
    "                cost: the cost function for the model\n",
    "        '''\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_x, labels=labels_y))\n",
    "\n",
    "        return cost\n",
    "    \n",
    "    def get_model_accy(self, logits, y):\n",
    "        '''\n",
    "            Calculate the model's accuracy\n",
    "            Parameters:\n",
    "                logits: logits output of the neural network\n",
    "                y: the corresponding labels for the logits\n",
    "            Returns:\n",
    "                accuracy: the model's accuracy\n",
    "        '''\n",
    "        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def get_model_opt(self, cost, learning_rate, beta1):\n",
    "        '''\n",
    "            Create the model optimizer\n",
    "            Parameters:\n",
    "                cost: The model's cost function\n",
    "                learning_rate: The learning rate for the optimizer\n",
    "                beta1: The exponential decay rate for the 1st moment estimates\n",
    "            Returns:\n",
    "                opt: The model optimizer set with learning and beta rates, and to minimize the cost function           \n",
    "        '''\n",
    "\n",
    "        # The following line allows for batch normalization to update population statistics\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): \n",
    "            opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(cost)\n",
    "\n",
    "        return opt\n",
    "\n",
    "    def train_model(self, *args, batch_size=64, epochs=1):\n",
    "        '''\n",
    "            Train the CNN using the batches\n",
    "            Paramters: \n",
    "                X: The entire training dataset\n",
    "                y: The corresponding labels\n",
    "                learning_rate: The learning rate for the optimizer\n",
    "                beta1: The exponential decay rate of the 1st moment for the optimizer\n",
    "                batch_size: The size of the batches for training\n",
    "                epochs: The number of epochs to train the model\n",
    "        '''\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        accy_training = [] # To store the model accuracy at certain intervals during training\n",
    "        accy_val = []\n",
    "        print_every = 10 # Print the losses at this number of intervals\n",
    "        save_every = 100 # Save the losses at this number of intervals\n",
    "        n_batches = len(X_train) // batch_size\n",
    "              \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for e in range(epochs):\n",
    "                for ii, (batch_x, batch_y) in enumerate(self.get_batches(X_train, y_train, batch_size)):\n",
    "                    print(ii)\n",
    "                    # Train the model\n",
    "                    _ = sess.run(opt, feed_dict={input_x: batch_x, labels_y: batch_y, is_training: True})\n",
    "                    \n",
    "                    # Show training loss and accuracy every few steps\n",
    "                    if ii % print_every == 0:\n",
    "                        train_loss = cost.eval({input_x: batch_x, labels_y: batch_y, is_training: False})\n",
    "                        train_accy =  accy.eval({input_x: batch_x, labels_y: batch_y, is_training: False})\n",
    "                        print(\"Epochs {}/{}...\".format(e + 1, epochs),\n",
    "                              \"Batch {}/{}...\".format(ii + 1, n_batches),\n",
    "                              \"Training Loss: {:.4f}...\".format(train_loss),\n",
    "                              \"Training Accuracy: {:.4f}\".format(train_accy))\n",
    "                    \n",
    "                    # Show and save the validation loss every few steps\n",
    "                    if ii % save_every == 0:\n",
    "                        # Read in the validation images from their filenames \n",
    "                        val_batch = self.get_batches(X_validate, y_validate, len(X_validate))\n",
    "                        val_imgs, y = next(val_batch)\n",
    "                        val_loss = cost.eval({input_x: val_imgs, labels_y: y_validate, is_training: False})\n",
    "                        val_accy = accy.eval({input_x: val_imgs, labels_y: y_validate, is_training: False})\n",
    "                        losses.append()\n",
    "                        print(\"Epochs {}/{}...\".format(e + 1, epochs),\n",
    "                              \"Validation Loss: {:.4f}...\".format(val_loss),\n",
    "                              \"Validation Accuracy: {:.4f}\".format(val_accy))\n",
    "                        accy_training.append(train_accy)\n",
    "                        accy_val.append(val_accy)\n",
    "            \n",
    "            print(\"Training Complete...Calculating Test Loss and Accuracy\")\n",
    "            # Read in the test images from their filenames \n",
    "            test_imgs, _ = self.get_batches(X_test, y_test, len(X_test))\n",
    "            # Calculate the test accuracy after training\n",
    "            test_loss = cost.eval({input_x: test_imgs, labels_y: y_test, is_training: False})\n",
    "            test_accy = accy.eval({input_x: test_imgs, labels_y: y_test, is_training: False})\n",
    "            print(\"Test Loss: {:.4f}...\".format(test_loss),\n",
    "                  \"Test Accuracy: {:.4f}\".format(test_accy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "learning_rate = 0.001\n",
    "beta1 = 0.05\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "n_classes = udacity_labels.shape[-1]\n",
    "\n",
    "net = CNN()\n",
    "input_x, labels_y, is_training = net.get_model_inputs(n_classes)\n",
    "logits = net.build_network(input_x, is_training, n_classes=n_classes, alpha=alpha)\n",
    "cost = net.get_model_loss(logits, labels_y)\n",
    "accy = net.get_model_accy(logits, labels_y)\n",
    "opt = net.get_model_opt(cost, learning_rate, beta1)\n",
    "\n",
    "net.train_model(X_train, y_train, X_validate, y_validate, input_x, labels_y, is_training, cost, accy, opt, \n",
    "                batch_size=batch_size, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     if len(frame.bboxes) >= frame.samples:\n",
    "#         total_bboxes = [item for sublist in frame.bboxes for item in sublist]\n",
    "#         frame.centroids = total_bboxes\n",
    "#         frame.bboxes = []\n",
    "#         heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "#         heat = add_heat(heat, total_bboxes)\n",
    "#         heat = 255 * (heat - np.min(heat)) / (np.max(heat) - np.min(heat))\n",
    "#         heat3d = np.dstack((heat, np.zeros_like(image[:,:,0]).astype(np.float), np.zeros_like(image[:,:,0]).astype(np.float)))\n",
    "#         for box in total_bboxes:\n",
    "#             cv2.rectangle(heat3d, box[0], box[1], (0, 0, 255), 1)\n",
    "#         frame.image = heat3d\n",
    "#     else:\n",
    "#         if frame.centroids:\n",
    "#             heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "#             heat = add_heat(heat, frame.centroids)\n",
    "#             heat = 255 * (heat - np.min(heat)) / (np.max(heat) - np.min(heat))\n",
    "#             heat3d = np.dstack((heat, np.zeros_like(image[:,:,0]).astype(np.float), np.zeros_like(image[:,:,0]).astype(np.float)))\n",
    "#             for box in frame.centroids:\n",
    "#                 cv2.rectangle(heat3d, box[0], box[1], (0, 0, 255), 1)\n",
    "#             frame.image = heat3d"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
