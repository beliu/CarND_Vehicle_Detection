{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Import the necessary libraries and packages\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "from collections import defaultdict\n",
    "import PyQt4\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract the target objects from the larger Udacity image and store them to a folder\n",
    "def extract_images(data, filepath):\n",
    "    for ii, img in enumerate(data):\n",
    "         # Read in each one by one\n",
    "        file = img[0]\n",
    "        image = mpimg.imread(file)\n",
    "        # Isolate the region in the image that contains the object\n",
    "        xmin, ymin, xmax, ymax = img[1], img[2], img[3], img[4]\n",
    "        image = image[ymin:ymax + 1, xmin:xmax + 1]\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        filler = '00000'\n",
    "        mpimg.imsave(filepath + 'image_' + filler[:len(filler) - len(str(ii))] + str(ii) + '.jpg', image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv=None):\n",
    "    image = np.copy(img)\n",
    "    if conv != 'RGB':\n",
    "        transform = \"cv2.cvtColor(image, cv2.COLOR_\" + conv + \")\"\n",
    "        features = eval(transform)\n",
    "    else:\n",
    "        features = image\n",
    "    \n",
    "    return features\n",
    "    \n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32), channel='all'):\n",
    "    if channel == 'all':\n",
    "        channel = np.arange(3)\n",
    "    \n",
    "    features = []\n",
    "    for ch in channel:\n",
    "        color = cv2.resize(img[:, :, ch], size).ravel()\n",
    "        features.append(color)\n",
    "    spatial_features = np.concatenate(features)\n",
    "            \n",
    "    return spatial_features\n",
    "\n",
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256), channel='all'):   \n",
    "    # Compute the histogram of the color channels separately\n",
    "    if channel == 'all':\n",
    "        channel = np.arange(3)\n",
    "        \n",
    "    features = []\n",
    "    hist_features = []\n",
    "    for ch in channel:\n",
    "        channel_hist = np.histogram(img[:, :, ch], bins=nbins, range=bins_range)\n",
    "        features.append(channel_hist[0])\n",
    "    hist_features = np.concatenate(features)\n",
    "        \n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True, trans_sqrt=True, block_norm='L1'):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), block_norm=block_norm,\n",
    "                                  transform_sqrt=trans_sqrt, visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), block_norm=block_norm,\n",
    "                       transform_sqrt=trans_sqrt, visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(data, img_format='png', spatial_dict=None, hist_dict=None, hog_dict=None):\n",
    "    \n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    \n",
    "    # Iterate through the list of images\n",
    "    for file in data:\n",
    "        single_img_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file) \n",
    "        if ((img_format == 'jpg') | (file[-4:] == '.jpg')):\n",
    "            image = image.astype(np.float32) / 255\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        \n",
    "        if spatial_dict is not None:\n",
    "            cspace = spatial_dict['conv']\n",
    "            spatial_size = spatial_dict['size']\n",
    "            channels = spatial_dict['channels']\n",
    "            image_conv = convert_color(image, cspace)\n",
    "            spatial_features = bin_spatial(image_conv, size=(spatial_size, spatial_size), channel=channels)\n",
    "            single_img_features.append(spatial_features)\n",
    "            \n",
    "        if hist_dict is not None:\n",
    "            cspace = hist_dict['conv']\n",
    "            hist_bins = hist_dict['nbins']\n",
    "            bin_range = hist_dict['bin_range']\n",
    "            channels = hist_dict['channels']\n",
    "            image_conv = convert_color(image, cspace)\n",
    "            hist_features = color_hist(image_conv, nbins=hist_bins, bins_range=(0, 256), channel=channels)\n",
    "            single_img_features.append(hist_features)\n",
    "\n",
    "        if hog_dict is not None:\n",
    "            cspace = hog_dict['conv']\n",
    "            orient = hog_dict['orient']\n",
    "            pix_per_cell = hog_dict['pix_per_cell']\n",
    "            cell_per_block = hog_dict['cell_per_block']\n",
    "            channels = hog_dict['channels']       \n",
    "            trans_sqrt = hog_dict['trans_sqrt']\n",
    "            block_norm = hog_dict['block_norm']\n",
    "            image_conv = convert_color(image, cspace)  \n",
    "            hog_features = []\n",
    "            if channels == 'all':\n",
    "                channels = np.arange(3)\n",
    "            \n",
    "            for ch in channels:\n",
    "                hog_features.append(get_hog_features(image_conv[:,:,ch], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True, trans_sqrt=trans_sqrt, block_norm=block_norm))\n",
    "            hog_features = np.ravel(hog_features)                      \n",
    "            single_img_features.append(hog_features)\n",
    "            \n",
    "        features.append(np.concatenate(single_img_features))\n",
    "\n",
    "    # Return list of feature vectors\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save a dictionary into a pickle file\n",
    "def save_to_pickle(data, key_name, file_name):\n",
    "    if len(file_name) > 1:\n",
    "        for d, k, f in zip(data, key_name, file_name):\n",
    "            pickle_data = {k: d}\n",
    "            pickle.dump(pickle_data, open(f + '.p', \"wb\"))\n",
    "    else:\n",
    "        pickle_data = {}\n",
    "        for d, k in zip(data, key_name):\n",
    "            pickle_data[k] = d\n",
    "        print(pickle_data)\n",
    "        pickle.dump(pickle_data, open(file_name[0] + '.p', \"wb\"))\n",
    "    \n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_training_files(GTI=False, KITTI=False, udacity=False, len_non_cars=None):\n",
    "    \n",
    "    car_gti = []\n",
    "    kitti_cars = []\n",
    "    car_gti_far = []\n",
    "    car_gti_left = []\n",
    "    car_gti_midclose = []\n",
    "    car_gti_right = []\n",
    "    \n",
    "    if GTI:\n",
    "        # Collect the filenames for all car images in the dataset\n",
    "        car_gti_far = glob.glob('../data/vehicles/GTI_Far/*png')\n",
    "        car_gti_left = glob.glob('../data/vehicles/GTI_Left/*png')\n",
    "        car_gti_midclose = glob.glob('../data/vehicles/GTI_MiddleClose/*png')\n",
    "        car_gti_right = glob.glob('../data/vehicles/GTI_Right/*png')\n",
    "        car_gti = car_gti_far + car_gti_left + car_gti_midclose + car_gti_right\n",
    "    if KITTI:\n",
    "        kitti_cars = glob.glob('../data/vehicles/KITTI_extracted/*png')\n",
    "\n",
    "    # Collect the filenames for all non-car images in the dataset\n",
    "    non_car_gti = glob.glob('../data/non_vehicles/GTI/*png')\n",
    "    extras_non_cars = glob.glob('../data/non_vehicles/Extras/*png')\n",
    "    \n",
    "    car_files = np.array(car_gti + kitti_cars)\n",
    "    non_car_files = np.array(non_car_gti + extras_non_cars)\n",
    "    non_car_files = shuffle(non_car_files)\n",
    "    if len_non_cars: \n",
    "        n_sample = len_non_cars\n",
    "    else:\n",
    "        n_sample = len(non_car_files)\n",
    "    \n",
    "    udacity_car_files = np.array([])\n",
    "    if udacity:\n",
    "        udacity_df = pd.read_csv('../data/labels.csv')\n",
    "        udacity_cars_df = udacity_df.loc[(udacity_df.label == 'car') & (udacity_df.occluded == 0)]\n",
    "\n",
    "        udacity_car_idx = udacity_cars_df.index.tolist()\n",
    "        udacity_car_files = np.array(glob.glob('../data/udacity_cropped/*jpg'))\n",
    "        udacity_car_files = udacity_car_files[udacity_car_idx]\n",
    "\n",
    "    all_img_files = np.hstack((non_car_files[:n_sample], car_files, udacity_car_files))\n",
    "    img_type_labels = np.hstack((np.zeros(n_sample), np.ones(len(car_gti_far)), np.ones(len(car_gti_left)) * 2, \n",
    "                                     np.ones(len(car_gti_midclose)) * 3, np.ones(len(car_gti_right)) * 4, \n",
    "                                     np.ones(len(kitti_cars)) * 5, np.ones(len(udacity_car_files)) * 6))\n",
    "\n",
    "    print('No. of GTI car files: {}'.format(len(car_gti)))\n",
    "    print('No. of KITTI car files: {}'.format(len(kitti_cars)))\n",
    "    print('No. of Udacity car files: {}'.format(len(udacity_car_files)))\n",
    "    print('Total number of car files: {}'.format(len(car_files) + len(udacity_car_files)))\n",
    "    print('Tota number of non-car files: {}'.format(n_sample))\n",
    "    print('Total number of images: {}'.format(all_img_files.shape))\n",
    "    print('Total number of labels: {}'.format(img_type_labels.shape))\n",
    "\n",
    "    train_img_files = np.copy(all_img_files)\n",
    "    train_labels_copy = np.copy(img_type_labels)\n",
    "    \n",
    "    return train_img_files, train_labels_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_img_files, train_labels_copy = make_training_files(GTI=True, KITTI=True, udacity=True)\n",
    "\n",
    "# img_format = 'png'\n",
    "# ## Here is a list of possible color spaces to use\n",
    "# '''cv2.COLOR_RGB2HSV\n",
    "#    cv2.COLOR_RGB2LUV\n",
    "#    cv2.COLOR_RGB2HLS\n",
    "#    cv2.COLOR_RGB2YUV\n",
    "#    cv2.COLOR_RGB2YCrCb'''\n",
    "\n",
    "# spatial_dict = {'conv': 'RGB2YCrCb', 'size': 32, 'channels': 'all'}\n",
    "# hist_dict = {'conv': 'RGB2YCrCb', 'nbins': 32, 'bin_range': (0, 256), 'channels': 'all'}\n",
    "# hog_dict = {'conv': 'RGB2YCrCb', 'orient': 9, 'pix_per_cell': 8, 'cell_per_block': 2, 'channels': 'all',\n",
    "#             'trans_sqrt': True, 'block_norm': 'L1'}\n",
    "\n",
    "# # X_train_features = extract_features(train_img_files, spatial_dict=spatial_dict, hist_dict=hist_dict, \n",
    "# #                                     hog_dict=hog_dict)\n",
    "# # file_end = 'ycrcb_massive_data'\n",
    "\n",
    "# # X_train_features = np.array(X_train_features).astype(np.float32)\n",
    "# # # Fit a per-column scaler\n",
    "# # X_scaler = StandardScaler().fit(X_train_features)\n",
    "# # # Apply the scaler to X\n",
    "# # scaled_X = X_scaler.transform(X_train_features)\n",
    "# print('X train features shape is {}'.format(X_train_features.shape))\n",
    "# print('Scaled X features is {}'.format(scaled_X.shape))\n",
    "\n",
    "# save_to_pickle([scaled_X, train_labels_copy, X_scaler], ['features', 'labels', 'scaler'], \n",
    "#                ['../pickle/scaled_X_' + file_end])\n",
    "# save_to_pickle([spatial_dict, hist_dict, hog_dict], ['spatial', 'hist', 'hog'], \n",
    "#                ['../pickle/dict_' + file_end])\n",
    "\n",
    "# rand_state = np.random.randint(0, 100)\n",
    "# # Shuffle and split the data into a training and test set\n",
    "# X_train, X_validate, y_train, y_validate = train_test_split(scaled_X, train_labels_copy, test_size=0.2, \n",
    "#                                                             stratify=train_labels_copy, random_state=rand_state)\n",
    "# print('X_train shape is {}'.format(X_train.shape))\n",
    "# print('y_train shape is {}'.format(y_train.shape))\n",
    "# print('X_validate shape is {}'.format(X_validate.shape))\n",
    "# print('y_validate shape is {}'.format(y_validate.shape))\n",
    "\n",
    "# print(y_train[:20])\n",
    "# y_train[y_train != 0] = 1.\n",
    "# y_validate[y_validate != 0] = 1.\n",
    "# print(y_train[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Use a linear SVC \n",
    "# svc = LinearSVC()\n",
    "# # Check the training time for the SVC\n",
    "# t=time.time()\n",
    "# svc.fit(X_train, y_train)\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# print('Test Accuracy of SVC = ', round(svc.score(X_validate, y_validate), 4))\n",
    "# save_to_pickle([svc, hog_dict['trans_sqrt'], hog_dict['block_norm']], ['svc', 'trans_sqrt', 'block_norm'], \n",
    "#                ['../pickle/svc_pickle_' + file_end])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_end = 'ycrcb'\n",
    "dict_pickle = pickle.load( open(\"../pickle/scaled_X_\" + file_end + \".p\", \"rb\") )\n",
    "X_scaler = dict_pickle['scaler']\n",
    "\n",
    "dict_pickle = pickle.load( open(\"../pickle/dict_\" + file_end + \".p\", \"rb\") )\n",
    "spatial_dict = dict_pickle['spatial']\n",
    "hist_dict = dict_pickle['hist']\n",
    "hog_dict = dict_pickle['hog']\n",
    "\n",
    "dict_pickle = pickle.load( open(\"../pickle/svc_pickle_\" + file_end + \".p\", \"rb\" ) )\n",
    "svc = dict_pickle['svc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling \n",
    "# and make predictions\n",
    "def find_cars(img, img_format, xstart, xstop, ystart, ystop, scale, X_scaler, svc, hog_dict, \n",
    "              spatial_dict=None, hist_dict=None, print_pred=False):\n",
    "                \n",
    "    # Extract the Hog parameters\n",
    "    hg_cspace = hog_dict['conv']\n",
    "    orient = hog_dict['orient']\n",
    "    pix_per_cell = hog_dict['pix_per_cell']\n",
    "    cell_per_block = hog_dict['cell_per_block']\n",
    "    hg_ch = hog_dict['channels']       \n",
    "    trans_sqrt = hog_dict['trans_sqrt']\n",
    "    block_norm = hog_dict['block_norm']\n",
    "    \n",
    "    if hg_ch == 'all':\n",
    "        hg_ch = np.arange(3)\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    if img_format == 'jpg':\n",
    "        img = img.astype(np.float32) / 255\n",
    "     \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    img_tosearch = img[ystart:ystop, xstart:xstop, :]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv=hg_cspace)\n",
    "    bboxes = [] # Store the coordinates of the bounded boxes\n",
    "\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1] / scale), \n",
    "                                     np.int(imshape[0] / scale)))\n",
    "    chs = []\n",
    "    for ch in hg_ch:\n",
    "        chs.append(ctrans_tosearch[:,:,ch])\n",
    "\n",
    "    # Define blocks and steps\n",
    "    nxblocks = (chs[0].shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (chs[0].shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "\n",
    "    hogs = []\n",
    "    for ch in chs:\n",
    "        hog_feature = get_hog_features(ch, orient, pix_per_cell, cell_per_block, \n",
    "                                feature_vec=False, trans_sqrt=trans_sqrt, block_norm=block_norm)\n",
    "        hogs.append(hog_feature)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "\n",
    "            # Extract HOG for this patch\n",
    "            hog_list = []\n",
    "            for hg in hogs:    \n",
    "                hog_vect = hg[ypos:ypos+nblocks_per_window, \n",
    "                                 xpos:xpos+nblocks_per_window].ravel()\n",
    "                hog_list.append(hog_vect)   \n",
    "            hog_features = np.hstack(hog_list)\n",
    "        \n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "           # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, \n",
    "                                xleft:xleft+window], (64,64))\n",
    "\n",
    "            # Get color features\n",
    "            spatial_features = np.array([])\n",
    "            hist_features = np.array([])\n",
    "            if spatial_dict is not None:\n",
    "                sp_cspace = spatial_dict['conv']\n",
    "                spatial_size = spatial_dict['size']\n",
    "                sp_ch = spatial_dict['channels']\n",
    "                spatial_features = bin_spatial(subimg, size=(spatial_size, spatial_size), channel=sp_ch)\n",
    "            if hist_dict is not None:\n",
    "                hs_cspace = hist_dict['conv']\n",
    "                hist_bins = hist_dict['nbins']\n",
    "                bin_range = hist_dict['bin_range']\n",
    "                hi_ch = hist_dict['channels']\n",
    "                hist_features = color_hist(subimg, nbins=hist_bins, bins_range=(0, 256), channel=hi_ch)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            features = np.hstack((spatial_features, hist_features, hog_features))\n",
    "            test_features = X_scaler.transform(features.reshape(1, -1))       \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            if print_pred:\n",
    "                print('prediction: {}'.format(test_prediction))\n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left+xstart, ytop_draw+ystart),\n",
    "                (xbox_left+xstart+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                bboxes.append(((xbox_left + xstart, ytop_draw + ystart), \n",
    "                               (xbox_left + xstart + win_draw, ytop_draw + win_draw + ystart)))\n",
    "                \n",
    "    return draw_img, bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    output_heatmap = np.copy(heatmap)\n",
    "    output_heatmap[output_heatmap < threshold] = 0\n",
    "    \n",
    "    # Return thresholded map\n",
    "    return output_heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "def make_labeled_bboxes(image, bbox_list, threshold, draw, color=(0, 0, 255), thickness=3):\n",
    "    out_bboxes = {} # A dict of all the bounded boxes for each car found in this image\n",
    "    \n",
    "    if len(bbox_list) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Accumulate bounded boxes across several frames and then apply heat-map with threshold\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    heat = add_heat(heat, bbox_list)\n",
    "    heat_map = apply_threshold(heat, threshold)\n",
    "    labels = label(heat_map)\n",
    "\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        out_bboxes[car_number] = bbox\n",
    "        if draw:\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(image, bbox[0], bbox[1], color, thickness)\n",
    "    \n",
    "    if draw:\n",
    "        # Return the image and bboxes\n",
    "        return image, out_bboxes\n",
    "    else:\n",
    "        # Return the bboxes\n",
    "        return out_bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to keep track of data among frames\n",
    "class Frame():\n",
    "    def __init__(self):\n",
    "        self.count = 0 # Tracks the number of frames that have passed\n",
    "        self.bboxes = [] # Each entry in this list is the detection boxes for one frame; used for\n",
    "                         # accumulating detection boxes for heat map threshold\n",
    "        self.samples = 8 # How many frames should we collect boxes for\n",
    "#         self.centroids = defaultdict(list) # A list of the centroids of each bounding box around a car\n",
    "        self.image = None\n",
    "        self.detect_boxes = [] # A list of the bounded boxes surrounding a car detection\n",
    "        self.car_boxes = defaultdict(list) # A list of the bounded box surrounding an entire car\n",
    "        self.final_boxes = None\n",
    "        self.find_cars = True\n",
    "        self.heat = None\n",
    "        self.heat_record = []\n",
    "        self.t = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the function that processes each frame of the video to find cars and apply a box around them\n",
    "def process_image(image):\n",
    "    \n",
    "    frame.image = np.copy(image)\n",
    "    if frame.heat is None:\n",
    "        frame.heat = np.zeros_like(frame.image[:, :, 0])\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame.image, str(frame.count), (650, 150), font, 1, (200,255,155), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame.image, 't:' + str(frame.t), (700, 150), font, 1, (200,255,155), 2, cv2.LINE_AA)\n",
    "        \n",
    "    if frame.find_cars:\n",
    "        # Search for cars in the distance\n",
    "        xstart = 0\n",
    "        xstop = image.shape[1]\n",
    "        ystart = 400\n",
    "        ystop = 450\n",
    "        scale = 0.5\n",
    "        _, far_bboxes = find_cars(image, img_format, xstart, xstop, ystart, ystop, scale, X_scaler,\n",
    "                                  svc, hog_dict, spatial_dict, hist_dict)\n",
    "        # Search for cars in the middle\n",
    "        ystart = 400\n",
    "        ystop = 550\n",
    "        scale = 1\n",
    "        _, mid_bboxes = find_cars(image, img_format, xstart, xstop, ystart, ystop, scale, X_scaler, \n",
    "                                  svc, hog_dict, spatial_dict, hist_dict)\n",
    "        # Search for close cars\n",
    "        ystart = 400\n",
    "        ystop = 650\n",
    "        scale = 1.5\n",
    "        _, close_bboxes = find_cars(image, img_format, xstart, xstop, ystart, ystop, scale, X_scaler, \n",
    "                                    svc, hog_dict, spatial_dict, hist_dict)\n",
    "        \n",
    "        detect_boxes = far_bboxes + mid_bboxes + close_bboxes \n",
    "#         frame.detect_boxes.append(detect_boxes)\n",
    "        frame.detect_boxes += list(detect_boxes)\n",
    "    \n",
    "        for box in frame.detect_boxes:\n",
    "            cv2.rectangle(frame.image, box[0], box[1], (100, 100, 0), 2)\n",
    "        \n",
    "        frame.heat = add_heat(frame.heat, detect_boxes)\n",
    "        heat = np.copy(frame.heat)\n",
    "        frame.heat_record.append(heat)\n",
    "        \n",
    "        if car_accum:\n",
    "            # Accumulate bounded boxes across several frames and then apply heat-map with threshold\n",
    "            car_boxes = make_labeled_bboxes(frame.image, detect_boxes, \n",
    "                                            threshold=1, draw=False, color=(0, 150, 0), thickness=2)\n",
    "            for car, box in car_boxes.items():\n",
    "                frame.car_boxes[car] += list([box])\n",
    "\n",
    "            for _, mult_boxes in frame.car_boxes.items():\n",
    "                for box in mult_boxes:\n",
    "                    cv2.rectangle(frame.image, box[0], box[1], (0, 255, 0), thickness=3)\n",
    "\n",
    "        if frame.count >= frame.samples:\n",
    "            if car_accum:\n",
    "                car_boxes = []\n",
    "                for car, box in frame.car_boxes.items():\n",
    "                    car_boxes += box\n",
    "                # Accumulate bounded boxes across several frames and then apply heat-map with threshold\n",
    "                frame.image, frame.final_boxes = make_labeled_bboxes(frame.image, car_boxes,\n",
    "                                                           threshold=5, draw=True)\n",
    "            else:\n",
    "                # Accumulate bounded boxes across several frames and then apply heat-map with threshold\n",
    "                frame.image, frame.final_boxes = make_labeled_bboxes(frame.image, frame.detect_boxes, \n",
    "                                                           threshold=9, draw=True)\n",
    "            # Reset the store bboxes\n",
    "            frame.detect_boxes = []\n",
    "            frame.car_boxes = defaultdict(list)\n",
    "            frame.count = 0\n",
    "            frame.heat = None\n",
    "            frame.find_cars = False\n",
    "    else:\n",
    "        frame.track_car_boxes = []\n",
    "        adjustment = 0.05\n",
    "        for car, box in frame.final_boxes.items():\n",
    "            ystart = np.clip(np.int(box[0][1] * (1.0 - adjustment)), 0, frame.image.shape[0])\n",
    "            ystop = np.clip(np.int(box[1][1] * (1.0 + adjustment)), 0, frame.image.shape[0])\n",
    "            xstart = np.clip(np.int(box[0][0] * (1.0 - adjustment)), 0, frame.image.shape[1])\n",
    "            xstop = np.clip(np.int(box[1][0] * (1.0 + adjustment)), 0, frame.image.shape[1])\n",
    "            cv2.rectangle(frame.image, (xstart, ystart), (xstop, ystop), (0, 0, 0), 3)\n",
    "            single_car_boxes= []\n",
    "            scales = [0.5, 1.5, 1.75]\n",
    "            for scale in scales:\n",
    "                _, bboxes = find_cars(image, img_format, xstart, xstop, ystart, ystop, scale, X_scaler,\n",
    "                                       svc, hog_dict, spatial_dict, hist_dict)\n",
    "                single_car_boxes += bboxes\n",
    "            print('t {}'.format(frame.t))\n",
    "            print('single car boxes {}'.format(single_car_boxes))\n",
    "            frame.track_car_boxes += list(single_car_boxes)\n",
    "            print('track car boxes {}'.format(frame.track_car_boxes))\n",
    "            \n",
    "            for box in single_car_boxes:\n",
    "                cv2.rectangle(frame.image, box[0], box[1], (100, 0, 100), 3)\n",
    "            \n",
    "            frame.heat = add_heat(frame.heat, single_car_boxes)\n",
    "            \n",
    "        frame.heat_record.append(np.copy(frame.heat))\n",
    "        \n",
    "        # This is wrong. Use the latest frame.heat instead. In fact, modify this function to take \n",
    "        # in a heat map instead.\n",
    "        test_car_boxes = make_labeled_bboxes(frame.image, frame.track_car_boxes, threshold=1, draw=False)\n",
    "#         print(test_car_boxes)\n",
    "        for car, test_box in test_car_boxes.items():\n",
    "            cv2.rectangle(frame.image, test_box[0], test_box[1], (0, 255, 255), 1)\n",
    "        \n",
    "        if frame.t == 15:\n",
    "            asdfsadf\n",
    "            \n",
    "#             # For there to be an intersection of boxes, min R edge > max L edge and min bot edge > max top edge\n",
    "#             org_box = frame.final_boxes[car]\n",
    "#             min_right_edge = min(test_box[1][0], org_box[1][0])\n",
    "#             max_left_edge = max(test_box[0][0], org_box[0][0])\n",
    "#             min_bottom_edge = min(test_box[1][1], org_box[1][1])\n",
    "#             max_top_edge = max(test_box[0][1], org_box[0][1])\n",
    "#             overlap = ((max_left_edge, max_top_edge), (min_right_edge, min_bottom_edge))\n",
    "#             overlap_area = (min_right_edge - max_left_edge) * (min_bottom_edge - max_top_edge)\n",
    "#             org_area = (org_box[1][0] - org_box[0][0]) * (org_box[1][1] - org_box[0][1])\n",
    "#             overlap_ratio = overlap_area / np.float(org_area)\n",
    "            \n",
    "#             if ((min_right_edge > max_left_edge) & (min_bottom_edge > max_top_edge)):\n",
    "#                 cv2.rectangle(frame.image, overlap[0], overlap[1], (255, 0, 0), 3)\n",
    "                \n",
    "#             if ((min_right_edge > max_left_edge) & (min_bottom_edge > max_top_edge) & (overlap_ratio >= 0.75)):   \n",
    "#                 frame.car_boxes[car] = test_car_boxes\n",
    "#                 cv2.rectangle(frame.image, test_car_boxes[0], test_car_boxes[1], (0, 0, 255), 6)\n",
    "#             else:\n",
    "#                 frame.car_boxes.pop(car, None)\n",
    "#                 frame.find_cars = True\n",
    "#                 break\n",
    "        \n",
    "        if frame.count >= frame.samples:\n",
    "            frame.find_cars = True\n",
    "            frame.heat = None\n",
    "            frame.count = 0\n",
    "            \n",
    "    frame.count += 1\n",
    "    frame.t += 1\n",
    "    \n",
    "    return frame.image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/39 [00:02<01:27,  2.30s/it]\u001b[A\n",
      "  5%|▌         | 2/39 [00:04<01:25,  2.30s/it]\u001b[A\n",
      "  8%|▊         | 3/39 [00:06<01:22,  2.30s/it]\u001b[A\n",
      " 10%|█         | 4/39 [00:09<01:20,  2.29s/it]\u001b[A\n",
      " 13%|█▎        | 5/39 [00:11<01:17,  2.29s/it]\u001b[A\n",
      " 15%|█▌        | 6/39 [00:13<01:15,  2.28s/it]\u001b[A\n",
      " 18%|█▊        | 7/39 [00:16<01:13,  2.29s/it]\u001b[A\n",
      " 21%|██        | 8/39 [00:18<01:10,  2.28s/it]\u001b[A\n",
      " 23%|██▎       | 9/39 [00:20<01:08,  2.28s/it]\u001b[A\n",
      " 26%|██▌       | 10/39 [00:22<01:06,  2.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 11\n",
      "single car boxes [((831, 460), (863, 492)), ((839, 460), (871, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 460), (895, 492)), ((871, 412), (903, 444)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 460), (935, 492)), ((911, 428), (943, 460)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n",
      "track car boxes [((831, 460), (863, 492)), ((839, 460), (871, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 460), (895, 492)), ((871, 412), (903, 444)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 460), (935, 492)), ((911, 428), (943, 460)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      " 28%|██▊       | 11/39 [00:24<00:57,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 11\n",
      "single car boxes [((1053, 404), (1085, 436)), ((1053, 412), (1085, 444)), ((1061, 404), (1093, 436)), ((1077, 420), (1109, 452)), ((1085, 428), (1117, 460)), ((1085, 468), (1117, 500)), ((1093, 468), (1125, 500)), ((1101, 428), (1133, 460)), ((1109, 428), (1141, 460)), ((1205, 428), (1237, 460)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500)), ((1077, 404), (1173, 500)), ((1101, 404), (1197, 500)), ((1097, 380), (1209, 492))]\n",
      "track car boxes [((831, 460), (863, 492)), ((839, 460), (871, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 460), (895, 492)), ((871, 412), (903, 444)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 460), (935, 492)), ((911, 428), (943, 460)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492)), ((1053, 404), (1085, 436)), ((1053, 412), (1085, 444)), ((1061, 404), (1093, 436)), ((1077, 420), (1109, 452)), ((1085, 428), (1117, 460)), ((1085, 468), (1117, 500)), ((1093, 468), (1125, 500)), ((1101, 428), (1133, 460)), ((1109, 428), (1141, 460)), ((1205, 428), (1237, 460)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500)), ((1077, 404), (1173, 500)), ((1101, 404), (1197, 500)), ((1097, 380), (1209, 492))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 12\n",
      "single car boxes [((831, 460), (863, 492)), ((839, 460), (871, 492)), ((847, 460), (879, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 412), (903, 444)), ((871, 420), (903, 452)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 412), (911, 444)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 460), (935, 492)), ((903, 468), (935, 500)), ((911, 428), (943, 460)), ((911, 436), (943, 468)), ((911, 444), (943, 476)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n",
      "track car boxes [((831, 460), (863, 492)), ((839, 460), (871, 492)), ((847, 460), (879, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 412), (903, 444)), ((871, 420), (903, 452)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 412), (911, 444)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 460), (935, 492)), ((903, 468), (935, 500)), ((911, 428), (943, 460)), ((911, 436), (943, 468)), ((911, 444), (943, 476)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      " 31%|███       | 12/39 [00:25<00:51,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 12\n",
      "single car boxes [((1053, 412), (1085, 444)), ((1061, 404), (1093, 436)), ((1085, 468), (1117, 500)), ((1093, 468), (1125, 500)), ((1101, 428), (1133, 460)), ((1109, 428), (1141, 460)), ((1141, 420), (1173, 452)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500)), ((1077, 404), (1173, 500)), ((1101, 404), (1197, 500)), ((1097, 380), (1209, 492))]\n",
      "track car boxes [((831, 460), (863, 492)), ((839, 460), (871, 492)), ((847, 460), (879, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 412), (903, 444)), ((871, 420), (903, 452)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 412), (911, 444)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 460), (935, 492)), ((903, 468), (935, 500)), ((911, 428), (943, 460)), ((911, 436), (943, 468)), ((911, 444), (943, 476)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492)), ((1053, 412), (1085, 444)), ((1061, 404), (1093, 436)), ((1085, 468), (1117, 500)), ((1093, 468), (1125, 500)), ((1101, 428), (1133, 460)), ((1109, 428), (1141, 460)), ((1141, 420), (1173, 452)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500)), ((1077, 404), (1173, 500)), ((1101, 404), (1197, 500)), ((1097, 380), (1209, 492))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 13\n",
      "single car boxes [((823, 428), (855, 460)), ((831, 436), (863, 468)), ((831, 460), (863, 492)), ((839, 436), (871, 468)), ((839, 460), (871, 492)), ((847, 428), (879, 460)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 412), (911, 444)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 444), (935, 476)), ((903, 460), (935, 492)), ((911, 428), (943, 460)), ((911, 436), (943, 468)), ((911, 444), (943, 476)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n",
      "track car boxes [((823, 428), (855, 460)), ((831, 436), (863, 468)), ((831, 460), (863, 492)), ((839, 436), (871, 468)), ((839, 460), (871, 492)), ((847, 428), (879, 460)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 412), (911, 444)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 444), (935, 476)), ((903, 460), (935, 492)), ((911, 428), (943, 460)), ((911, 436), (943, 468)), ((911, 444), (943, 476)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      " 33%|███▎      | 13/39 [00:27<00:47,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 13\n",
      "single car boxes [((1061, 404), (1093, 436)), ((1061, 412), (1093, 444)), ((1109, 428), (1141, 460)), ((1125, 420), (1157, 452)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500)), ((1077, 404), (1173, 500)), ((1101, 404), (1197, 500))]\n",
      "track car boxes [((823, 428), (855, 460)), ((831, 436), (863, 468)), ((831, 460), (863, 492)), ((839, 436), (871, 468)), ((839, 460), (871, 492)), ((847, 428), (879, 460)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 412), (911, 444)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 444), (935, 476)), ((903, 460), (935, 492)), ((911, 428), (943, 460)), ((911, 436), (943, 468)), ((911, 444), (943, 476)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492)), ((1061, 404), (1093, 436)), ((1061, 412), (1093, 444)), ((1109, 428), (1141, 460)), ((1125, 420), (1157, 452)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500)), ((1077, 404), (1173, 500)), ((1101, 404), (1197, 500))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 14\n",
      "single car boxes [((831, 460), (863, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 444), (935, 476)), ((903, 460), (935, 492)), ((903, 468), (935, 500)), ((911, 444), (943, 476)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((871, 380), (967, 476)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n",
      "track car boxes [((831, 460), (863, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 444), (935, 476)), ((903, 460), (935, 492)), ((903, 468), (935, 500)), ((911, 444), (943, 476)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((871, 380), (967, 476)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      " 36%|███▌      | 14/39 [00:29<00:44,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 14\n",
      "single car boxes [((1053, 412), (1085, 444)), ((1061, 404), (1093, 436)), ((1061, 412), (1093, 444)), ((1109, 396), (1141, 428)), ((1109, 428), (1141, 460)), ((1117, 420), (1149, 452)), ((1117, 428), (1149, 460)), ((1125, 428), (1157, 460)), ((1205, 428), (1237, 460)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500)), ((1077, 404), (1173, 500)), ((1101, 380), (1197, 476)), ((1101, 404), (1197, 500))]\n",
      "track car boxes [((831, 460), (863, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 420), (895, 452)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 428), (935, 460)), ((903, 444), (935, 476)), ((903, 460), (935, 492)), ((903, 468), (935, 500)), ((911, 444), (943, 476)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((871, 380), (967, 476)), ((831, 380), (943, 492)), ((859, 380), (971, 492)), ((1053, 412), (1085, 444)), ((1061, 404), (1093, 436)), ((1061, 412), (1093, 444)), ((1109, 396), (1141, 428)), ((1109, 428), (1141, 460)), ((1117, 420), (1149, 452)), ((1117, 428), (1149, 460)), ((1125, 428), (1157, 460)), ((1205, 428), (1237, 460)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500)), ((1077, 404), (1173, 500)), ((1101, 380), (1197, 476)), ((1101, 404), (1197, 500))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 15\n",
      "single car boxes [((831, 436), (863, 468)), ((831, 460), (863, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 404), (903, 436)), ((871, 420), (903, 452)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 436), (919, 468)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 460), (935, 492)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n",
      "track car boxes [((831, 436), (863, 468)), ((831, 460), (863, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 404), (903, 436)), ((871, 420), (903, 452)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 436), (919, 468)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 460), (935, 492)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492))]\n",
      "t 15\n",
      "single car boxes [((1061, 404), (1093, 436)), ((1061, 412), (1093, 444)), ((1093, 468), (1125, 500)), ((1093, 476), (1125, 508)), ((1109, 396), (1141, 428)), ((1109, 428), (1141, 460)), ((1117, 420), (1149, 452)), ((1117, 428), (1149, 460)), ((1125, 428), (1157, 460)), ((1173, 476), (1205, 508)), ((1205, 428), (1237, 460)), ((1213, 436), (1245, 468)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500))]\n",
      "track car boxes [((831, 436), (863, 468)), ((831, 460), (863, 492)), ((855, 436), (887, 468)), ((855, 460), (887, 492)), ((863, 436), (895, 468)), ((863, 460), (895, 492)), ((871, 404), (903, 436)), ((871, 420), (903, 452)), ((871, 436), (903, 468)), ((871, 460), (903, 492)), ((879, 436), (911, 468)), ((879, 444), (911, 476)), ((879, 460), (911, 492)), ((887, 404), (919, 436)), ((887, 412), (919, 444)), ((887, 436), (919, 468)), ((887, 460), (919, 492)), ((895, 404), (927, 436)), ((895, 412), (927, 444)), ((895, 420), (927, 452)), ((895, 460), (927, 492)), ((903, 460), (935, 492)), ((799, 404), (895, 500)), ((823, 380), (919, 476)), ((823, 404), (919, 500)), ((847, 380), (943, 476)), ((847, 404), (943, 500)), ((831, 380), (943, 492)), ((859, 380), (971, 492)), ((1061, 404), (1093, 436)), ((1061, 412), (1093, 444)), ((1093, 468), (1125, 500)), ((1093, 476), (1125, 508)), ((1109, 396), (1141, 428)), ((1109, 428), (1141, 460)), ((1117, 420), (1149, 452)), ((1117, 428), (1149, 460)), ((1125, 428), (1157, 460)), ((1173, 476), (1205, 508)), ((1205, 428), (1237, 460)), ((1213, 436), (1245, 468)), ((1005, 404), (1101, 500)), ((1029, 404), (1125, 500))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asdfsadf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-175>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-174>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    135\u001b[0m              for (k,v) in k.items()}\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-173>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[1;32m    347\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                            \u001b[0mffmpeg_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mffmpeg_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                            progress_bar=progress_bar)\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_temp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmake_audio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     for t,frame in clip.iter_frames(progress_bar=progress_bar, with_times=True,\n\u001b[0;32m--> 209\u001b[0;31m                                     fps=fps, dtype=\"uint8\"):\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwithmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                 \u001b[0;31m# Update and print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-138>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-020af51bf1bd>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0masdfsadf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m#             # For there to be an intersection of boxes, min R edge > max L edge and min bot edge > max top edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdfsadf' is not defined"
     ]
    }
   ],
   "source": [
    "img_format = 'jpg'\n",
    "car_accum = False\n",
    "frame = Frame()\n",
    "frame.samples = 10\n",
    "clip1 = VideoFileClip(\"../test_video.mp4\", audio=False)\n",
    "road_clip = clip1.fl_image(process_image)\n",
    "%time road_clip.write_videofile(\"../delete_this.mp4\", audio=False, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(len(frame.heat_record))\n",
    "fig, axes = plt.subplots(3, 2)\n",
    "# print(axes.ravel())\n",
    "dev = 10\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.imshow(frame.heat_record[i + dev], cmap='hot')\n",
    "    ax.set_title('Frame {}'.format(i + dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "heat = frame.heat_record[15]\n",
    "heat_map = apply_threshold(heat, 1)\n",
    "labels = label(heat_map)\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ((799, 380), (970, 499)),\n",
       " 2: ((1005, 396), (1156, 507)),\n",
       " 3: ((1205, 428), (1244, 467)),\n",
       " 4: ((1173, 476), (1204, 507))}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes = make_labeled_bboxes(frame.image, frame.track_car_boxes, threshold=1, draw=False)\n",
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((831, 436), (863, 468)),\n",
       " ((831, 460), (863, 492)),\n",
       " ((855, 436), (887, 468)),\n",
       " ((855, 460), (887, 492)),\n",
       " ((863, 436), (895, 468)),\n",
       " ((863, 460), (895, 492)),\n",
       " ((871, 404), (903, 436)),\n",
       " ((871, 420), (903, 452)),\n",
       " ((871, 436), (903, 468)),\n",
       " ((871, 460), (903, 492)),\n",
       " ((879, 436), (911, 468)),\n",
       " ((879, 444), (911, 476)),\n",
       " ((879, 460), (911, 492)),\n",
       " ((887, 404), (919, 436)),\n",
       " ((887, 412), (919, 444)),\n",
       " ((887, 436), (919, 468)),\n",
       " ((887, 460), (919, 492)),\n",
       " ((895, 404), (927, 436)),\n",
       " ((895, 412), (927, 444)),\n",
       " ((895, 420), (927, 452)),\n",
       " ((895, 460), (927, 492)),\n",
       " ((903, 460), (935, 492)),\n",
       " ((799, 404), (895, 500)),\n",
       " ((823, 380), (919, 476)),\n",
       " ((823, 404), (919, 500)),\n",
       " ((847, 380), (943, 476)),\n",
       " ((847, 404), (943, 500)),\n",
       " ((831, 380), (943, 492)),\n",
       " ((859, 380), (971, 492)),\n",
       " ((1061, 404), (1093, 436)),\n",
       " ((1061, 412), (1093, 444)),\n",
       " ((1093, 468), (1125, 500)),\n",
       " ((1093, 476), (1125, 508)),\n",
       " ((1109, 396), (1141, 428)),\n",
       " ((1109, 428), (1141, 460)),\n",
       " ((1117, 420), (1149, 452)),\n",
       " ((1117, 428), (1149, 460)),\n",
       " ((1125, 428), (1157, 460)),\n",
       " ((1173, 476), (1205, 508)),\n",
       " ((1205, 428), (1237, 460)),\n",
       " ((1213, 436), (1245, 468)),\n",
       " ((1005, 404), (1101, 500)),\n",
       " ((1029, 404), (1125, 500))]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.track_car_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12cc304e0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heat = np.zeros_like(frame.image[:, :, 0])\n",
    "heat = add_heat(heat, frame.track_car_boxes)\n",
    "fig = plt.figure()\n",
    "plt.imshow(heat, cmap='hot')\n",
    "fig = plt.figure()\n",
    "plt.imshow(frame.heat, cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
